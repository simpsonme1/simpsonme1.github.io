<html>
    <head>
        <title>Software Engineering Blog</title>

    </head>


    <body>
        <h1>HW0: Introduction</h1>

        <p> I was born in Charleston, South Carolina. However, I have also lived in Alabama and Virginia before moving back to 
            Charleston when in seventh grade. I remained in Charleston until I graduated high school from Fort Dorchester, 
            after which my parents moved to Georgia. I am now a junior and a computer science major at College of Charleston. My faith, family, friends, and my 
            dog, an eleven year old lab mix, are a few things that are important in my life. My current favorite movie is A Star is Born (the new version). I also enjoy going to the beach and going for
            bike rides, and I have recently taken up knitting over the past year. (In other words, I have knitted far too many scarves to live in a state with such hot and humid
            weather.) I am excited to further my knowledge of computer science in this software engineering course this semester and to see where my acquired
            knowledge will take me in my future CS career.
        </p>
        
        <h1>HW1: Chapter 1</h1>
        
        
        <p>
            <strong>1.3</strong>        
        </p>
        <p>
            Four important attributes that all professional software should possess include acceptability, dependability and security, efficiency, and maintainability. Other
            attributes that may sometimes be significant may include: 1. creativity in order to appeal to a specific client/user base depending on the purpose of the software,
            2. backward compatibility in order for users to be able to continue using the software with older versions of files and data, 3. being innovative in order to keep up and 
            compete with other rapidly advancing and changing technologies (for example, that of other competing companies), and 4. portability in order to provide users with
            increased mobility of software on any device or operating system they may prefer.
        </p>
        
        
        <p>
            <strong>1.8</strong>        
        </p>
        <p>
           In my opinion, professional engineers should be licensed in the same way as doctors or lawyers in terms of ethical practices. Because the vast majority of society depends daily on the work by software
            engineers, their work could have potential detrimental effects. For example, if a software engineer is developing software for a doctor's office, a level of respect
            and confidentiality should be given to the patients when the developer has access to personal information that may be used maliciously if placed into the wrong hands.
            Software developers have a great knowledge base that allows them to work in a wide variety of fields, which most other professions do not possess. Therefore, the 
            dependability and trustworthiness of software developers is vital to the workings of an ethical society.
            
        </p>
        
        
        <p>
            <strong>1.9</strong>        
        </p>
        <p>
            PUBLIC: When developing a website for a large company, a software engineer should not implement a virus into the site that would infect users' computers for the purpose of stealing
            personal information, such as passwords, bank account information, etc.
        </p>
        <p>
            CLIENT AND EMPLOYER: If a bug is discovered in an online shopping website by the software engineer, it is expected that the bug will be fixed out of interest for both
            the client and employer. For example, if the website calculates an incorrect amount of state tax owed by the user at checkout, this could negatively effect both the
            client and employer.
        </p>
        <p>
            PRODUCT: If the developer realizes he/she does not have the proper skill set to perform a certain task, he/she should admit this fact and allow a developer with the proper
            expertise to handle the task.
        </p>
        <p>
            JUDGMENT: When a software engineer recognizes a potential overlooked problem in a team's code/work, he/she should know when to speak up about the problem rather than
            knowingly allowing the problematic work to be implemented into practice.
        </p>
        <p>
            MANAGEMENT: A software engineer should give credit where credit is due for work that is not theirs. It is common for developers to use previously written code, but credit
            should be given to the original developer of that code when needed.
        </p>
        <p>
            PROFESSION: Software engineers should do their best to meet proposed deadlines to clients and should not knowingly withhold critical information needed by the client.
        </p>
        <p>
            COLLEAGUES: When a colleage asks for aid on a task they are struggling with, a supportive software engineer will be willing to give advice in a non-condescending manner.
        </p>
        <p>
            SELF: With an ever growing amount of technology, a software engineer should continue to take courses and study new technological advances and innovations in their field.
        </p>
        
        
        <p>            
            <strong>1.10</strong>        
        </p>
        <p>
            To help counter terrorism, many countries are planning or have developed computer systems that track large numbers of their citizens and their actions. Clearly, this
            has privacy implications. If a software engineer found that this interfered with their personal ethics, he/she would technically be required to speak out against this
            and possibly resign from their position. However, this remains a problem of personal choice, as it may be seen as both ethical and unethical, depending on the point
            of view. For example, some may view any invasion of privacy as unethical, despite the reasoning behind it. On the other hand, if the US were to use such technology
            against an enemy country during a time of war or under suspicion of malicious acts against the US, some may perceive such use of technology justifiable. In this example,
            some may even consider it it unethical to not use such technology against another country in order to protect the USA's own citizens. In matters such as this, the ethics
            of working on the development of this type of system becomes a matter of personal choice and specific situations.
        </p>
        
        
        <h1>HW2: Reflections on software engineering practices</h1>
        
        <p>
            All three of the assigned readings, in one way or another, discuss the development costs that accompany any software development process and the methods that can help reduce and/or increase these costs. “No Silver Bullet” highlights this fact by stating that “the cost of software has always been development cost, not replication cost” (Brooks 17). However, the article also makes the point that software progress is not necessarily slow due to development costs. Rather, the high speed of hardware development makes the progress of software appear slow in comparison to hardware’s rapid innovations (Brooks 11). Nonetheless, methods such as code replication, top-down design, and version-controlled storage of files all aid in decreasing the amount of time it takes to push out usable software. 
        </p>
        
        <p>
            One such example of decrease in development cost is illustrated in George V. Neville-Neil’s “Kode Vicious”. The article states that the best way to avoid ending up in the pits of cherry-picking is to be sure to periodically merge whatever code that a developer is working against. In other words, a developer should “have a merged and tested branch ready to go when it is time for [the developer’s] project to resynchronize with the head of the development tree” (Neville-Neil 33). A related idea is reflected by Google’s practices in Rachel Potvin and Josh Levenberg’s article, “Why Google Stores Billions of Lines of Code in a Single Repository”. Google implements the trunk-based development strategy in order to efficiently manage their large repository, thereby decreasing development costs. This method also helps to alleviate the difficulties associated with the merging of branches (as in “Kode Vicious”), but does so by attempting to altogether avoid the “painful merges that often occur when it is time to reconcile long-lived branches” (82). Rather than developing on the branches themselves, revisions (such as bug fixes) are developed on mainline and subsequently cherry-picked into the branch if necessary. Because of the extremely vast repository that Google works out of (which is not the case for all software developers), this method is especially beneficial, as it allows newly committed code to be immediately seen and used by all other Google developers (82). Although there exist additional benefits to this trunk-based approach, there also exists drawbacks, such as the added costs of developing automated testing and “pre-submit” infrastructure. 
        </p>
        
        <p>This reflects the common trend of trade-off analysis throughout the software development process in general, as reflected in “No Silver Bullet”. The article states that software development is the only technology where one can choose to gain from “either improved performance or in reduced costs”, suggesting that improved performance comes with a host of development costs while reduced costs comes with a decrease in software performance (Brooks 11). This is further illustrated by the fact that “Google invests significant effort in maintaining code health to address some issues related to codebase complexity and dependency management” thanks to its large repository (Potvin & Levenberg 86). Despite potential benefits of working out of smaller repositories, Google has determined that the benefits of maintaining its current working repository outweighs its current costs of maintenance or that of downsizing into a non-monolithic source repository. This example suggests part of the reasoning behind Brooks’ belief that no “silver bullets” are likely to appear anytime soon due to the very nature of software, such as its trade-offs, among other factors.</p>
        



        <h1>HW3: Chapters 11 & 12</h1>

        <p>            
            <strong>11.4</strong>        
        </p>

        <p>The common characteristic of all architectural styles that are geared to supporting software fault tolerance is that the system architecture is designed to include redundant and diverse hardware and software. The importance of this can be seen through the replicated server approach, where redundancy, but not usually diversity, is provided. Because server hardware is often identical and run the same versions of software, they can cope with hardware failures but not the software failures that are not localized to a single machine. Thus, both diverse hardware and software is necessary for handling software design failure. Benefits of redundancy can be illustrated in replicated servers through the preserved system integrity if the hardware of one server were to fail and another server be forced to take over the unprocessed transactions.

        </p>

        <p>            
            <strong>11.7</strong>        
        </p>
        
        <p>
            It has been suggested that the control software for a radiation therapy machine, used to treat patients with cancer, should be implemented using N-version programming. Because of the currently extremely high costs for medical treatment, especially treatments such as radiation, I think this would be an acceptable suggestion, as N-version programming may be less expensive than self-checking architectures in systems for which a high level of availability is required. This decrease in cost for this technology may then help to lower the cost of radiation treatment for cancer patients. Although development costs would still be high due to the requirement for several different teams to develop different software versions, it would still be cheaper than self-checking architecture and would even add to the reliability of the machine. (This reliability is important because an overdose of radiation to a patient could be fatal.) Of course, this assumes that there is a need for high availability of the machine, which I believe there would be considering the high prevalence of cancer. Although reliability is often valued over availability in the medical field, I believe that both can be achieved in this specific case without the need for compromise.
        </p>

        <p>            
            <strong>11.9</strong>        
        </p>

        <p>
            You should explicitly handle all exceptions in a system that is intended to have a high level of availability in order to ensure that program exceptions do not cause system failures, as well as to continue normal operation after the exception has been processed. Because the system has a high level of availability, it is consistently relied on to function properly. Each time that an exception cannot be properly handled, someone is losing time and money that could be put towards a better use of time due to something that could have been avoided in the first place.
        </p>

        <p>            
            <strong>12.5</strong>        
        </p>

        <p>
            Five possible functional system requirements generated from the system safety requirements:
        </p>

        <p>
            1.	The system must allow for user override in case of an emergency or some unpredicted situation.
        </p>

        <p>
            2.	The amount of pressure to be applied to the brakes should be regulated based on current speed of the train and/or distance. For example, a braking that is too hard may also cause safety hazards for passengers, may cause damage to the train or its cargo, etc.
        </p>

        <p>
            3.	The speed of the train should be constantly calculated by the system.
        </p>

        <p>
            4.	A warning should be given to the train conductor in the event that there is a red light and/or the brakes need to be applied. A warning should also be given if there is a change in the speed limit ahead.
        </p>

        <p>
            5.	The system should offer alternate routes (those without red lights) for the conductor to take in the event that a segment of track is signaled with a red light.
        </p>
        
        
        <h1>HW4: Reflections on software failures</h1>
        
        <p>
            By the time I got to the last article for this week’s reading, “Why Software Projects Fail, and the Traps You Can Avoid That Could Spell Disaster”, it was obvious to me how spot-on its list of reasons was considering the failed software projects that we had just read about. What was shocking, however, was how such large companies and organizations could fail so miserably due to not meeting simple requirements as listed by this article, such as having unclear project requirements, insufficient time, and inadequate planning. This was surprising because these appear to be common sense factors to consider when working on any type of work, but especially work that could potentially cost millions or billions of dollars, time, and even people’s lives (such as in the failed Therac-25 cases). Although there may have been bugs in the software that may have contributed to the failure of the software overall, bugs are an expected hurdle in any programming feat. In fact, the article even stated that developers have come to expect failure.  The problem with bugs and/or failure is when humans fail to properly address them, such as by giving themselves adequate time for software testing, poor communication between team members, etc. For example, one issue with the spacecraft accidents was not lack of intelligence, but rather lack of communication between team members, so that engineers were not fully informed on how their piece of the puzzle was supposed to fit together with everybody else’s. If there were better communication between these teams, the engineers most likely would have been able to address common concerns across the board and would have been able to adapt their code to better fit the project goal as a whole. Additionally, chapter 13 emphasizes the practice of design for recovery under the assumption that a security failure could always occur, no matter how well-developed the engineer believes the code to be. Another aspect from these readings that surprised me was that the reuse of code from earlier working Therac radiation machine designs contributed to the eventual downfall of the Therac-25 software. Generally speaking, I had always thought that reuse of code was a positive thing that led to more confidence in the code as well as saved time and money. Although the reuse of the code in the Therac-25 system did not turn out how the engineers had expected, the reuse of the code was not the specific problem; rather, the problem was with the engineers who carelessly reused the code without applying its features or lack thereof to the current model at hand. In other words, it seems that most software failures occur not because of the lack of intelligence but because of the failure to follow through with testing and checking up on every single piece of the project (in other words, being detail-oriented). Chapter 14 of the book mentions collaborative checking, which air traffic controllers implement to constantly monitor the work of the rest of their team. This allows any mistakes made by one member of the team to have a much higher chance of being detected by some other member. This not only improves team communication but also ensures adequate testing, which is beneficial for software engineering practices as well. For example, in the FBI Fiasco articles, there was extremely poor communication between teams – to the point where many could not even agree on the exact scope of the project, much less the exact user requirements. However, if a similar system of checking each other’s work had been implemented, all teams would have been on the same page and would have been able to work much more efficiently rather than trying to rush and, instead, find the project behind schedule and over budget in the end.  All in all, these case studies have largely illustrated the lesson pointed out in the 2005 FBI Fiasco: “'Well, lesson No. 1: faster, cheaper, better. Pick two, but you can't have all three.”


        </p>


        <h1>HW5: Chapter 4 and reflections</h1>
        
        <p>
            <strong>4.5</strong>        
        </p>
        
        <p>Plausible user requirements for:</p>
        <p>a.	An unattended gas pump system that includes a credit card reader. The customer swipes the card through the reader, then specifies the amount of fuel required. The fuel is delivered and the customer's account debited.</p>
    
        <ul>
            <li>The system shall read the user’s card when it is swiped.</li>
            <li>The system shall ask for the user’s pin number. If the pin number is incorrect, the system shall reject the card.</li>
            <li>The system shall accept input from the user to specify the amount of fuel required.</li>
            <li>The system shall charge the user’s card based on the specified amount of fuel.</li>
            <li>The system shall dispense the specified amount of fuel.</li>
        </ul>
        
        <p>b.	The cash-dispensing function in a bank ATM.</p>
        
        <ul>
            <li>The ATM shall allow for a card to be swiped or inserted and ask for the user pin number.</li>
            <li>The ATM shall ask for a specified amount of cash to be dispensed.</li>
            <li>The system shall deny the specified amount if the amount is greater than the amount in the account.</li>
            <li>The system shall give the card back to the user.</li>
            <li>The system shall offer the use a receipt for the transaction.</li>
        </ul>
        
        <p>c.	In an internet banking system, a facility that allows customers to transfer funds from one account held with the bank to another account with the same bank.</p>
        
        <ul>
            <li>The system shall verify that both accounts are with the same bank.</li>
            <li>The system shall ask for the amount to be transferred, the account information to withdraw the amount from, and the account information to deposit the amount into.</li>
            <li>The system shall verify that the amount of money to be withdrawn from an account is less than or equal to the amount currently in the specified account.</li>
            <li>The system shall transfer the correct amount from the correct account and into the current account.</li>
        </ul>
        
        
        <p>
            <strong>4.6</strong>        
        </p>
        
        <p>An engineer responsible for drawing up a system requirements specification might keep track of the relationships between function and non-functional requirements by creating a relationship schema, such as in database concepts. A similar approach to the relationship schema would allow for the engineer to easily visualize relationships between the requirements. Some revision, such as using squares for functional requirements and ovals for non-functional requirements, may be useful as well.</p>
        
        
        <p>
            <strong>4.7</strong>        
        </p>
        
        <p>Set of use cases for an ATM:</p>
        <ul>
            <li>A user may deposit cash.</li>
            <li>A user may deposit a check.</li>
            <li>A user may withdraw a specified amount of cash.</li>
            <li>A user may check his/her balance.</li>
            <li>A user may wish to view his/her account.</li>
        </ul>

        <p><strong>Reflection:</strong></p>

        <p>A common concern among the articles includes privacy and safety. In the article about the Tire Pressure Monitoring System (TPMS), the authors point out the apparent lack of concern for the safety of auto drivers due to the lack of security enacted on TPMS, including location privacy risks, lack of input-validation on incoming data, and spoofing dashboard warnings. Although many believed that there was little to be concerned about security-wise, the article points out several very valid security issues. Though some may nonetheless believe the authors’ concerns to be over dramatic, those who seek to act maliciously will find creative ways to do so, and I would never underestimate a person’s potential malice; the extreme lengths and creativity of criminals have been proven time and time again. The Security and Privacy in Your Car Act of 2015, however, seeks to address concerns like the ones brought up in the TPMS article. One point that stood out to me in the act was the fact that users should be “given the option of terminating the collection and retention of driving data.” User override of software is important because bugs and security issues can always exist in software, no matter how well-developed the engineer believes the code to be. Another important point that I believe the act addresses is the required ability to not only detect but also report and prevent the interception of data and/or control of the vehicle. Simply detecting a potential threat does nothing to help the cause if efforts are not made to also report the threat in order to learn more about the threats and to prevent the threat from causing its intended harm. Test-driven development (TDD), as the last assigned reading discusses, would be beneficial in addressing these security and privacy threats by allowing developers increased awareness of and concentration on software requirements in general, including security. The fact that every single line of code is tested using the TDD method would decrease the potential for bugs within software, and the increased emphasis on writing effective tests would aid in security as well by ensuring the proper functioning of all code. In fact, I believe that many, if not all, of the past software failures that we have previously discussed in this class could have been prevented if this method of development were implemented, as it addresses the major problematic themes (i.e. overconfidence in software, unclear requirements, etc.) that appeared throughout each case study of the software failures.</p>

        
        
        <h1>HW6: Chapter 2</h1>
        
        <p><strong>2.1</strong></p>
        
        <p><u>A system to control antilock braking in a car:</u> I would suggest using the waterfall model as a basis for managing the development of this system because of the 
        safety-critical aspect that a braking system presents for an automobile. Therefore, the specification and design documents must be complete so that security analysis
        may be performed on the system before its actual deployment.</p>
        
        <p><u>A virtual reality system to support software maintenance:</u> For this system, implementing the integration and configuration approach may be best because
        this is a general-purpose system that would have many features in order for it to be able to adequately maintain software, and these tyeps of stand-alone application systems are
        commonly included in the reuse-oriented approach. Adapting the system for use in specific applications using this method would be much cheaper and more efficient if the main
        chunks for the system were already developed.</p>
        
        <p><u>A university accounting system that replaces an existing system:</u> The integration and configuration approach would best support development of this system 
            because many of the functions of the old system would remain the same for the new system since it is an accounting system with a specific purpose. The old system could
        then be adapted to fit user requirements for the new system, which should include aspects of the incremental development method as well to ensure that the user's likely
            changing requirements are being met as efficiently as possible.</p>
        
        <p><u>An interactive travel planning system that helps users plan journeys with the lowest environmental impact:</u> Because user feedback would be crucial to the success of
        this system, an incremental development approach would be suggested. This method will ease the burden of constant user feedback that will most likely change the requirements
        of the system while it is in the process of development as well as after it is deployed. Therefore, this approach will make it cheaper and easier to make changes in the
        software while making it easier to access user feedback in the first place.</p>
        

    </body>



</html>
