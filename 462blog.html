<html>
    <head>
        <title>Software Engineering Blog</title>

        <link rel="stylesheet" href="myStyleSheet.css">

    </head>

    <body>
        <h1><center>Welcome to my CSCI 462 Software Engineering Practicum Blog!</center></h1>

        <br>

        <h2><center>Introduction</center></h2>

        <p><center>Hello! My name is Megan Simpson and I am a third year computer science student at College of Charleston. I am originally from Charleston but have moved around a few times and now reside in Gumbranch, Georgia when not in Charleston for school. Hot chocolate, bike riding, knitting, and spending time with my friends, family, and dog are just a few of my favorite things. My dog, Cuddy, is a lab-mix and loves to go for rides in the car to Dunkin and Starbucks as much as I do (he has a deep love for puppuccinos). I am also in the process of creating my own website to sell my knitted creations, including warm, soft scarves and hats galore, which allows me to combine my passions for both creativity and computer science. I hope to further my passion for computer science throughout this software engineering practicum course by expanding my knowledge base and gaining valuable experience in preparation for my future occupation.</center></p>

        <center><p>I've included a photo of Cuddy below for your enjoyment.</p></center>
        <center><img src=".\cuddy462blog.jpg" id="Cuddy" WIDTH="300" HEIGHT="450"/></center>


        <br>
        <br>
        <br>
        <br>
        <br>

        <h2><center>Reflections on FOSS</center></h2>

        <p><center>So far throughout my experience in CSCI 462 Software Engineering Practicum, I have been grouped with four other students to form team 404-Name-Not-Found. We have scoured several websites in search of a free and open-source software project (FOSS) awaiting our team’s future contributions. Our team was able to find several FOSS projects meeting the requirements of being mature projects with online communities that are welcoming of newcomers. Although we had to sift through many projects that did not seem to meet these basic requirements, it was not a difficult task, nonetheless. What proved more difficult, however, was the actual building of the projects after downloading the project code. There were definitely projects with more detailed and helpful instructions for building the project compared to others. In the end, our team chose Zulip to add our contributions to, as it met all requirements but also had easy-to-follow instructions for building the code, which each member of our team was able to do in a timely manner. Additionally, Zulip appears to be an extremely practical tool that each of our group members can use in our everyday lives – how cool it would be to contribute to something that we would actually use.</center></p>
        <p><center>After reading the assigned article, “The Cathedral and the Bazaar” by Eric Steven Raymond, it was easy to see the benefits of open-source projects like the one my team will be contributing to throughout the semester. One thing that stood out to me in the article was that one reason the open-source Bazaar development model works so well is simply because of the interest in the work from those who are working on the projects. Usually, people are contributing to these open-source projects because they are invested in the work in some way – usually because they are users of the project or simply because they enjoy the types of problems that they are helping to solve. This makes a lot of sense when applied to our CSCI 462 Software Engineering Practicum course; we were able to find a project that our group actually <em>wanted</em> to work on. Another point that stood out to me while reading this article is the idea that “more heads are better than one”. This is something that most people have probably heard since grade school when being forced by teachers to work in pairs or groups with classmates, but I never actually took this saying seriously. I always thought that working in groups simply gave some people a free pass to contribute nothing to the team while a select few put in all the work. However, the people contributing to these open-source projects are generally all motivated to do so because of one reason or another, so I think that the “more heads are better than one” point is actually very reasonable and efficient in the Bazaar model development style. Additionally, there were a few points that Raymond made throughout the article that I had never thought of before, such as the fact that the Cathedral model often offers a limited pool of resources, leading to “resource marshalling”, and the absurd amount of overhead that accompanies this software development style. I think that it will be interesting to see how these points ring true after college graduation if I end up in a job that implements this Cathedral model. </center></p>



        <h2><center>Reflections on Open Source in Today's World</center></h2>

        <p><center>After reading a few articles from opensource.com, my knowledge and perspective within the field of Computer Science has certainly been shaped for the better. I really liked this assignment because, if I’m being honest, I probably would not have researched random computer science articles in my down time. I am happy that I was made to do so through this assignment because these articles brought to my attention certain topics that I never would have thought about otherwise and provided clarity on topics that I had heard of but never knew much about.</center></p>
        <p><center>For example, the first article I read, titled “6 Container Concepts You Need to Understand” by Mike Calizo, immediately caught my attention. The concept of containers was something that I had often seen and heard mentioned throughout my time as a computer science student, but I have never been officially taught about them in classes. A container is a solution to problems inherited from monolithic architectures, as monoliths can prevent organizations from moving quicky, – “the agile way” – so containers allow you to break monoliths into microservices. I learned from the article that Docker, a container itself, has essentially become synonymous with the term “container”. In fact, I am now using the Docker container for this course, CSCI 462, as part of building the Zulip project on a VM! I also learned of all the great benefits that come along with containers and the resulting popularity of them. Calizo states that “nearly any recent business innovation has containerization as a contributing factor, if not the central element”. It is easy to see why this would be so, knowing just a few of containers’ benefits, such as using microservices architecture to help software developers create functionality while failing small with the ability to recover faster from inevitable failures. This seems especially important to me since failure inherently comes along with software development. If developers can recover faster from failure, this could aid in staying on schedule, which proves to be another huge issue for software development. Other such benefits listed by Calizo include speed, agility, flexibility, and improved security with DevOps and DevSecOps, as the application is isolated from the host and other containerized applications. Another thing I found interesting is that containers aid in reuse of code, extending the concept of write-once and deploying anywhere. With this knowledge, it is easy to see how some believe that containers will eventually replace virtual machines.</center></p>
        <p><center>On a different, yet still intriguing, note, the second article I read deals with election fraud and its possible open-source solution. “Election Fraud: Is there an open-source solution?”, by Jeff Macharyas, discusses both the pros and cons of implementing open-source software with OSET Institute, which is working on new technology to ensure that every vote is counted as it was cast. Macharyas illustrates the need for this type of software by describing one of many similar voting incidents where a malfunctioning voting machine denied a vote for one candidate and changed the vote to support an opposing candidate. Macharyas goes further by stating that almost every election has reports of machines behaving in this manner and that the majority of these malfunctions are software-based. The fact that many voting security vulnerabilities are software-based was somewhat surprising to me, although not totally shocking, because many election voting frauds that I hear about involve actions by people themselves, such as deliberately trashing ballots to prevent them from being counted. A few underlying causes of these software problems include the fact that many voting machines are running outdated software built on 1990s technology, and even new machines are running Windows 7, which was scheduled to lose maintenance and support in January of 2020. Thus, the benefits of open-source software (discussed in “The Cathedral and the Bazaar”, which my previous blog post discusses) are thought to be able to handle the demand for the updates to voting machines. Nonetheless, complex licensing processes are involved with this open-source, dual-sandbox method. The article goes on to state that that all legitimate requests to work on the code for OSET will be honored, although the code is not yet accessible to the public. I think it would be pretty neat for a person to be able to say that they helped create software to aid in fairer voting, one of the most important privileges that we have as United States citizens.</center></p>
        

        <h2><center>What's Happening?</center></h2>

        <p><center>While searching for articles within the IEEE Software database, “Gamification” by Dirk Basten happened to pique my interest. Basten defines gamification as applying game-related elements to nongame contexts. A few of Basten’s examples of gamification include eBay’s star ratings and PayPal’s progress bars that help motivate users to complete their profiles. This was an interesting article to me because it seems to relate a lot to the concept of persuasive technology, which I have been trying to implement into my research with Dr. Ghosh, my computer science research advisor. Although I have read several articles on persuasive technology for my research work, I have not yet seen any of them use the phrase “gamification”. However, several of the articles on persuasive technology have mentioned implementation of games, which is similar, in efforts to influence a person’s behavior. Similarly, Basten does not mention the phrase “persuasive technology” in this article. Nonetheless, the two are alike in their motive to change user behavior; the main difference seems to be that gamification focuses more on the business domain – or at least in this specific article.</center></p>
        <p><center>The concept that stood out most to me in gamification was the need to motivate the user, which is an important aspect of persuasive technology as well. This reminded me of the BJ Fogg Behavior Model, which I have also researched with Dr. Ghosh. The model basically states that if a person has both the motivation and ability to respond to a prompt, or call-to-action, then the person will complete the action – otherwise, the person will not. Although there were several concepts within Basten’s article that corresponded with the Fogg Behavior Model, the model was not mentioned by name. Nonetheless, one of the points made within Basten’s article states that if gamification allows for unclear rules that lead to users cheating the system, then productivity may drop for the users who sense that they are at a disadvantage due those who may take advantage of the system. This corresponds to the Fogg Behavioral Model because feeling at a disadvantage can lead to low motivation. Thus, even if the person has the ability to complete the desired call to action, the person will not do so because motivation is lacking. </center></p>
        <p><center>Another point by Basten that I found particularly interesting is that gamification is not effective if taken with a one-size-fits-all approach. In other words, gamification requires a meaningful design. This point also relates to my undergraduate research because I am attempting to implement memes within a virtual pair programming assistant. The catch, however, is that the memes must correlate to the bot user’s interests in order to have a positive effect in hopes of further motivating the user (as is the goal in gamification). This motivation associated with meaningful design of either gamification or persuasive technology may increase the user’s motivation enough to be able to influence user behavior.</center></p>
        <p><center>Because of the seemingly widespread acceptance of the Fogg Behavioral Model and its correlations with many of the points made within the article, it seems to me that gamification is not merely the buzzword that critics claim it to be. Although critics claim that many people do not respond to gamification, this may simply be due to the fact that specific gamification specifications were poorly implemented for certain models (i.e., using the one-size-fits-all approach). When analyzing the effectiveness of persuasive technology as a whole, it seems quite effective based off various other articles. Thus, this leads me to coincide with Basten’s points. </center></p>


        <h2><center>Stupid or Solid?</center></h2>

        <p><center>One theme that I noticed among several of the points made by the articles is to not include more than you have to. For example, the Interface Segregation Principle states that programmers should not implement methods that are not used. If a programmer only wants to implement part of an interface, the programmer should create a new interface that includes only the functionality that the client code requires. Thus, the interface is instead fully implemented. Abiding by this principle allows for low coupling and high cohesion, desirable characteristics for code. Another example is that classes should stick to their purpose and should not have multiple responsibilities, according to the Single Responsibility Principle. Thus, the programmer should not give a class more responsibility than it actually needs. If necessary, a new class should be created instead to give the extra responsibility to. Additionally, the article states that getter and setter methods should only be implemented in the code when they are absolutely necessary, and variables should be set to private by default. Thus, the code does not have more functionality than it needs. This theme of not including more than is necessary seems to be prevalent within the field of computer science as a whole, not merely in programming. For example, one best practice for computer security is to provide only the minimum level of permissions to users and files. Otherwise, more permissions than necessary are likely to cause security breaches with possibly severe consequences. </center></p>
        <p><center>While reading these articles, I was shocked at the fact that students in beginning programming courses were not taught about several of the points that were made. In fact, I had never heard of many of the terms used before, such as the Singleton pattern, despite the fact that it is “probably the most well-known design pattern” as according to William Durand. Because Durand suggests that the Singleton pattern be avoided at all times, despite its popularity, this could be a contributing reason for my previous ignorance to the term. In other words, the fact that the Singleton pattern often leads to tight coupling may have been the reason that our beginning computer programming course professors did not mention the term. Thinking back on my computer programming courses in Python and Java, I remember my professors focusing more on what we should do, rather than what not to do. For example, the Single Responsibility Principle was heavily emphasized, while other parts of SOLID were touched on in varying degrees as well. One big thing, however, that I feel should have been emphasized more in my programming classes is testability of code. While it was mentioned that students should test their code, testing was done on a superficial level and never was the term “tight coupling” mentioned in relation to testing practices. Overall, it seemed strange while reading these articles that, being a third year computer science student, I did not have previous knowledge of several of the points made. Thus, the articles were an enlightening read, helping to build on what I already knew but also offering new knowledge and things to remember for my future programming endeavors. In general, I think that many of the readings we have had so far in CSCI 362/462 have been beneficial in allowing students to see other perspectives and real-life implementation of both S.T.U.P.I.D. and S.O.L.I.D. code.</center></p>


        <h2><center>Release Early and Often</center></h2>

        <p><center>Before reading the assigned chapters for this week’s blog post, I had always heard that documentation is important. However, this week’s readings have definitely emphasized just how important proper documentation is and why this is so. Additionally, I never realized that there were so many rules about proper documentation. Considering how important it is, I was surprised that, as a computer science student, I was never officially taught proper documentation skills until my last year before graduation. I was simply told to comment the code in my programs before I turned them in to the professor for a grade, and its importance was only briefly touched on. Thus, I was not very surprised when I read that “people are going to tell you that documentation doesn’t matter” because it did not seem to matter all that much to myself prior to my CSCI 362 and 462 Software Engineering courses. Although I was told how important it is, the reasoning behind why it is so important was never stressed. </center></p>
        <p><center>Throughout my time working on the Zulip open-source project for CSCI 462 so far this semester, however, this disconnect has become much clearer for me, building on top of what I learned throughout CSCI 362. Without proper documentation, it is incredibly difficult to contribute to the project, as my team has already discovered. In fact, our team chose not to contribute to several other potential open-source projects at the beginning of the semester simply because they did not have good documentation on how to build their development environments. In addition, while a lot of code in the Zulip (our team’s chosen open-source project) repository is documented, not all of it is documented well. In other words, some of the comments within the codebase are quite vague. Our textbook explicitly states that comments should be clear and specific. As a newcomer looking at poorly documented code, it is impossible for me to look through all of the code’s comments and know what the functionality of the code is. When done well, however, I am able to grasp the purpose of the code and how it works. Upon seeing the benefits of well-documented code, I have a new appreciation for open-source and its contributors who take the time to complete proper documentation to be used for years to come. </center></p>
        <p><center>Another take-away from the readings this week is that documentation can be a full-time job in itself. When done correctly, however, it can save a lot of time in the long run. Additionally, I feel more motivated to contribute to the open-source project that I am working on when I can quickly understand the code that I am looking at simply by reading its documentation. This allows me, as well as all other contributors, to use my time efficiently. This supports our textbook’s claim that properly preparing software allows it to be well-used long after the development period. The textbook also makes a good point, which I had not thought of previously, that contributions to an open-source project is something that can be put on a resume as a by-product of this course.</center></p>


        <h2><center>Chapter 5</center></h2>

        <p><center>This blog post is in response to Chapter 5 Domain Class Development from <em>Client-Centered Software Development The Co-FOSS Approach</em> by Allen B. Tucker. This chapter deals with a lot of terminology and ideas that were new to me. First, I learned that “domain classes are the central element in a CO-FOSS product that is customized to fit the needs of a single client [and]… capture the vocabulary used in the client’s own working environment, so that the terminology reflected in the software has familiar meaning to the clients who use it.” This makes a lot of sense to work a domain class in this way because the software is ultimately being built for the client to use, not for the software developer to use. Thus, it should be built with the client in mind and made as user-friendly as possible; this simply seems like a good business model and practice overall. </center></p>
        <p><center>The chapter discusses the idea of reuse, which we have discussed some in the previous software engineering course, CSCI 362. Despite the benefits that we discussed in CSCI 362 as well as those in the chapter itself, it actually seems like it would be more work to reuse code. The developer would first have to search for code suitable for his or her purposes, not to mention hoping that the code is documented well enough to understand without having to go through line-by-line in order to comprehend its functionality. On top of this, even if the code is well-documented, the developer still has to go through all the code to take out what is not necessary and then add any functions still needed. This seems like it would be especially annoying and time-consuming because the developer then has to figure out the logic behind the original code and try to think in a similar manner as the original programmer. The original developer’s thought process is likely different (though not necessarily better or worse) than the way the current developer will think through the problems and subsequent solutions. However, I can see how reuse would still be beneficial when dealing with a huge codebase; in this case, it may actually be faster to read rather than write all new code. Additionally, reuse seems useful for “checking your work”; in other words, reuse of code seems beneficial in the fact that a software developer could use existing code to compare with their own to ensure that they are not missing crucial or convenient functions, although any problems with the code should be found within the testing stage anyways, making this unnecessary and time-consuming as well. I also think that when a programmer writes code him or herself, the programmer better understands its functionality.</center></p>
        <p><center>One thing I found interesting within the chapter is the statement that “too many comments can hide bad code (i.e., they can be “used as a deodorant,” so to speak), while too few can made code difficult to read”. I most definitely agree that too few comments can make code difficult to read, especially after having worked on contributing to my team’s chosen open-source project throughout this course. Several code files that I have looked at so far have not been well commented, often times having extremely vague comments that do nothing to explain the code’s function. However, it shocked me that having too many comments could be a bad thing, although it would make sense if a person were over relying on comments in order to understand the code and, thus, practically ignoring the actual functionality of the code. I also noticed that the chapter discussed several points that were also discussed in the past STUPID/SOLID reading assignment, such as minimizing coupling, having good documentation, and creating cohesion within a class.</center></p>


        <h2><center>Chapter 6</center></h2>

        
        <h2><center>Chapter 9</center></h2>


        <h2><center>Meeting Charleston</center></h2>

        <p><center>I chose to attend a meeting hosted by the Charleston Women in Tech group. Due to the COVID-19 pandemic, the event was hosted via Zoom, although it does not seem like the content of the event suffered from it. Speaker Valerie Warnock gave a presentation titled “Upgrading Your Social Media Presence”. If I’m being honest, I did not originally expect to get much out of this presentation – especially as someone who does not care to post much on social media as of right now. However, my outlook on the presentation quickly changed. Valerie made the presentation quite interesting and engaging with audience polls that addressed questions regarding our current social media presence. The first poll, for example, asked each audience member which social media platform(s) we have active accounts for. To my surprise, LinkedIn was the highest voted social media platform, which I previously did not even consider a typical social media platform. I did not realize how popular LinkedIn is, and I only had an account because I was forced to make one my freshman year of college of part of an FYE class. As a college freshman, I did not realize the importance of a LinkedIn profile in job searching. </center></p>
        <p><center>Warnock continued her presentation with discussion on upgrading social media presence in personal, professional, and legacy categories and continued engaging the audience with relevant polls. I had previously been exposed to a lot of the information she gave, such as the possibility of getting fired from a job based on something you post on social media, privacy concerns, and security settings. However, her personal anecdotes emphasized these points, such as the fact that she was able to find out where an absolute stranger worked, his address, name, and a newspaper article containing his picture – all based only on the monogram on his shirt and the fact that he lived somewhere on Kiawah Island, which she picked up on simply from every day-type conversation. She was able to do so completely within legal means using public records and social media.</center></p>
        <p><center>She then gave several helpful tips and reminders regarding what to put on a resume versus what to include in a LinkedIn profile, and she gave several “insider” tips on what employers actually look for in potential employees when viewing resumes and LinkedIn profiles. For example, as an employer herself, Valerie Warnock often scrolls all the way to the bottom of a potential employee’s LinkedIn profile to gain as much information about the person as possible through their old posts and activity. One especially interesting piece of advice that she gave is to be very careful about who you follow and which posts you “like”. An example she gave is that clicking the “like” button on an innocent post that was posted by a known racist can make others view you as a racist as well simply by following the known racist and interacting with their posts. Overall, I left the meeting feeling inspired to up my game specifically on LinkedIn and with a better sense on how to recognize how others, and especially potential employers, may view my social media posts. Warnock definitely succeeded in persuading me of the importance of carefully managing all of my social media platforms, including ones like GitHub that many people may not consider “social media”.</center></p>

        


    </body>
</html>
